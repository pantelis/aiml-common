{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following example was taken from the examples code of the excellent [Tensorflow Probability API](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py) and is very instructive. Note that this was originally developed for TF 1.x and is being adapted to TF 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trains a variational auto-encoder (VAE) on binarized MNIST.\n",
    "\n",
    "    The VAE defines a generative model in which a latent code `Z` is sampled from a\n",
    "    prior `p(Z)`, then used to generate an observation `X` by way of a decoder\n",
    "    `p(X|Z)`. The full reconstruction follows\n",
    "\n",
    "    ```none\n",
    "    X ~ p(X)              # A random image from some dataset.\n",
    "    Z ~ q(Z | X)          # A random encoding of the original image (\"encoder\").\n",
    "    Xhat ~ p(Xhat | Z)       # A random reconstruction of the original image\n",
    "                            #   (\"decoder\").\n",
    "    ```\n",
    "\n",
    "    To fit the VAE, we assume an approximate representation of the posterior in the\n",
    "    form of an encoder `q(Z|X)`. We minimize the KL divergence between `q(Z|X)` and\n",
    "    the true posterior `p(Z|X)`: this is equivalent to maximizing the evidence lower\n",
    "    bound (ELBO),\n",
    "\n",
    "    ```none\n",
    "    -log p(x)\n",
    "    = -log int dz p(x|z) p(z)\n",
    "    = -log int dz q(z|x) p(x|z) p(z) / q(z|x)\n",
    "    <= int dz q(z|x) (-log[ p(x|z) p(z) / q(z|x) ])   # Jensen's Inequality\n",
    "    =: KL[q(Z|x) || p(x|Z)p(Z)]\n",
    "    = -E_{Z~q(Z|x)}[log p(x|Z)] + KL[q(Z|x) || p(Z)]\n",
    "    ```\n",
    "\n",
    "    -or-\n",
    "\n",
    "    ```none\n",
    "    -log p(x)\n",
    "    = KL[q(Z|x) || p(x|Z)p(Z)] - KL[q(Z|x) || p(Z|x)]\n",
    "    <= KL[q(Z|x) || p(x|Z)p(Z)                        # Positivity of KL\n",
    "    = -E_{Z~q(Z|x)}[log p(x|Z)] + KL[q(Z|x) || p(Z)]\n",
    "    ```\n",
    "\n",
    "    The `-E_{Z~q(Z|x)}[log p(x|Z)]` term is an expected reconstruction loss and\n",
    "    `KL[q(Z|x) || p(Z)]` is a kind of distributional regularizer. See\n",
    "    [Kingma and Welling (2014)][1] for more details.\n",
    "\n",
    "    This script supports both a (learned) mixture of Gaussians prior as well as a\n",
    "    fixed standard normal prior. You can enable the fixed standard normal prior by\n",
    "    setting `mixture_components` to 1. Note that fixing the parameters of the prior\n",
    "    (as opposed to fitting them with the rest of the model) incurs no loss in\n",
    "    generality when using only a single Gaussian. The reasoning for this is\n",
    "    two-fold:\n",
    "\n",
    "    * On the generative side, the parameters from the prior can simply be absorbed\n",
    "        into the first linear layer of the generative net. If `z ~ N(mu, Sigma)` and\n",
    "        the first layer of the generative net is given by `x = Wz + b`, this can be\n",
    "        rewritten,\n",
    "\n",
    "        s ~ N(0, I)\n",
    "        x = Wz + b\n",
    "            = W (As + mu) + b\n",
    "            = (WA) s + (W mu + b)\n",
    "\n",
    "        where Sigma has been decomposed into A A^T = Sigma. In other words, the log\n",
    "        likelihood of the model (E_{Z~q(Z|x)}[log p(x|Z)]) is independent of whether\n",
    "        or not we learn mu and Sigma.\n",
    "\n",
    "    * On the inference side, we can adjust any posterior approximation\n",
    "        q(z | x) ~ N(mu[q], Sigma[q]), with\n",
    "\n",
    "        new_mu[p] := 0\n",
    "        new_Sigma[p] := eye(d)\n",
    "        new_mu[q] := inv(chol(Sigma[p])) @ (mu[p] - mu[q])\n",
    "        new_Sigma[q] := inv(Sigma[q]) @ Sigma[p]\n",
    "\n",
    "        A bit of algebra on the KL divergence term `KL[q(Z|x) || p(Z)]` reveals that\n",
    "        it is also invariant to the prior parameters as long as Sigma[p] and\n",
    "        Sigma[q] are invertible.\n",
    "\n",
    "    This script also supports using the analytic KL (KL[q(Z|x) || p(Z)]) with the\n",
    "    `analytic_kl` flag. Using the analytic KL is only supported when\n",
    "    `mixture_components` is set to 1 since otherwise no analytic form is known.\n",
    "\n",
    "    Here we also compute tighter bounds, the IWAE [Burda et. al. (2015)][2].\n",
    "\n",
    "    These as well as image summaries can be seen in Tensorboard. For help using\n",
    "    Tensorboard see\n",
    "    https://www.tensorflow.org/guide/summaries_and_tensorboard\n",
    "    which can be run with\n",
    "    `python -m tensorboard.main --logdir=MODEL_DIR`\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "\n",
    "# Dependency imports\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import urllib\n",
    "# import tensorflow.compat.v1 as tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'learning_rate' is defined twice. First from /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Initial learning rate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tfd \u001b[39m=\u001b[39m tfp\u001b[39m.\u001b[39mdistributions\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m IMAGE_SHAPE \u001b[39m=\u001b[39m [\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m flags\u001b[39m.\u001b[39;49mDEFINE_float(\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m, default\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, help\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mInitial learning rate.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m flags\u001b[39m.\u001b[39mDEFINE_integer(\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_steps\u001b[39m\u001b[39m\"\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m5001\u001b[39m, help\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of training steps to run.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m flags\u001b[39m.\u001b[39mDEFINE_integer(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlatent_size\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     default\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     help\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of dimensions in the latent code (z).\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_defines.py:366\u001b[0m, in \u001b[0;36mDEFINE_float\u001b[0;34m(name, default, help, lower_bound, upper_bound, flag_values, required, **args)\u001b[0m\n\u001b[1;32m    364\u001b[0m parser \u001b[39m=\u001b[39m _argument_parser\u001b[39m.\u001b[39mFloatParser(lower_bound, upper_bound)\n\u001b[1;32m    365\u001b[0m serializer \u001b[39m=\u001b[39m _argument_parser\u001b[39m.\u001b[39mArgumentSerializer()\n\u001b[0;32m--> 366\u001b[0m result \u001b[39m=\u001b[39m DEFINE(\n\u001b[1;32m    367\u001b[0m     parser,\n\u001b[1;32m    368\u001b[0m     name,\n\u001b[1;32m    369\u001b[0m     default,\n\u001b[1;32m    370\u001b[0m     help,\n\u001b[1;32m    371\u001b[0m     flag_values,\n\u001b[1;32m    372\u001b[0m     serializer,\n\u001b[1;32m    373\u001b[0m     required\u001b[39m=\u001b[39;49mrequired,\n\u001b[1;32m    374\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    375\u001b[0m _register_bounds_validator_if_needed(parser, name, flag_values\u001b[39m=\u001b[39mflag_values)\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_defines.py:104\u001b[0m, in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, required, **args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDEFINE\u001b[39m(  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     parser,\n\u001b[1;32m     71\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     required\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     78\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Registers a generic Flag object.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[39m  NOTE: in the docstrings of all DEFINE* functions, \"registers\" is short\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m    a handle to defined flag.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m   \u001b[39mreturn\u001b[39;00m DEFINE_flag(\n\u001b[1;32m    105\u001b[0m       _flag\u001b[39m.\u001b[39;49mFlag(parser, serializer, name, default, help, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs), flag_values,\n\u001b[1;32m    106\u001b[0m       module_name, required)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_defines.py:140\u001b[0m, in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name, required)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m# Copying the reference to flag_values prevents pychecker warnings.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m fv \u001b[39m=\u001b[39m flag_values\n\u001b[0;32m--> 140\u001b[0m fv[flag\u001b[39m.\u001b[39;49mname] \u001b[39m=\u001b[39m flag\n\u001b[1;32m    141\u001b[0m \u001b[39m# Tell flag_values who's defining the flag.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m module_name:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_flagvalues.py:439\u001b[0m, in \u001b[0;36mFlagValues.__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    433\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_module_defining_flag(name) \u001b[39m==\u001b[39m module_name \u001b[39mand\u001b[39;00m\n\u001b[1;32m    434\u001b[0m       \u001b[39mid\u001b[39m(module) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_module_id_defining_flag(name)):\n\u001b[1;32m    435\u001b[0m     \u001b[39m# If the flag has already been defined by a module with the same name,\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[39m# but a different ID, we can stop here because it indicates that the\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39m# module is simply being imported a subsequent time.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m   \u001b[39mraise\u001b[39;00m _exceptions\u001b[39m.\u001b[39mDuplicateFlagError\u001b[39m.\u001b[39mfrom_flag(name, \u001b[39mself\u001b[39m)\n\u001b[1;32m    440\u001b[0m short_name \u001b[39m=\u001b[39m flag\u001b[39m.\u001b[39mshort_name\n\u001b[1;32m    441\u001b[0m \u001b[39m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39m# modules if it's not registered.\u001b[39;00m\n",
      "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'learning_rate' is defined twice. First from /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Initial learning rate."
     ]
    }
   ],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"learning_rate\", default=0.001, help=\"Initial learning rate.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"max_steps\", default=5001, help=\"Number of training steps to run.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"latent_size\",\n",
    "    default=16,\n",
    "    help=\"Number of dimensions in the latent code (z).\")\n",
    "flags.DEFINE_integer(\"base_depth\", default=32, help=\"Base depth for layers.\")\n",
    "flags.DEFINE_string(\n",
    "    \"activation\",\n",
    "    default=\"leaky_relu\",\n",
    "    help=\"Activation function for all hidden layers.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"batch_size\",\n",
    "    default=32,\n",
    "    help=\"Batch size.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"n_samples\", default=16, help=\"Number of samples to use in encoding.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"mixture_components\",\n",
    "    default=100,\n",
    "    help=\"Number of mixture components to use in the prior. Each component is \"\n",
    "        \"a diagonal normal distribution. The parameters of the components are \"\n",
    "        \"intialized randomly, and then learned along with the rest of the \"\n",
    "        \"parameters. If `analytic_kl` is True, `mixture_components` must be \"\n",
    "        \"set to `1`.\")\n",
    "flags.DEFINE_bool(\n",
    "    \"analytic_kl\",\n",
    "    default=False,\n",
    "    help=\"Whether or not to use the analytic version of the KL. When set to \"\n",
    "        \"False the E_{Z~q(Z|X)}[log p(Z)p(X|Z) - log q(Z|X)] form of the ELBO \"\n",
    "        \"will be used. Otherwise the -KL(q(Z|X) || p(Z)) + \"\n",
    "        \"E_{Z~q(Z|X)}[log p(X|Z)] form will be used. If analytic_kl is True, \"\n",
    "        \"then you must also specify `mixture_components=1`.\")\n",
    "flags.DEFINE_string(\n",
    "    \"data_dir\",\n",
    "    default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"vae/data\"),\n",
    "    help=\"Directory where data is stored (if using real data).\")\n",
    "flags.DEFINE_string(\n",
    "    \"model_dir\",\n",
    "    default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"vae/\"),\n",
    "    help=\"Directory to put the model's fit.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"viz_steps\", default=500, help=\"Frequency at which to save visualizations.\")\n",
    "flags.DEFINE_bool(\n",
    "    \"fake_data\",\n",
    "    default=False,\n",
    "    help=\"If true, uses fake data instead of MNIST.\")\n",
    "flags.DEFINE_bool(\n",
    "    \"delete_existing\",\n",
    "    default=False,\n",
    "    help=\"If true, deletes existing `model_dir` directory.\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def _softplus_inverse(x):\n",
    "    \"\"\"Helper which computes the function inverse of `tf.nn.softplus`.\"\"\"\n",
    "    return tf.math.log(tf.math.expm1(x))\n",
    "\n",
    "\n",
    "def make_encoder(activation, latent_size, base_depth):\n",
    "    \"\"\"Creates the encoder function.\n",
    "\n",
    "    Args:\n",
    "        activation: Activation function in hidden layers.\n",
    "        latent_size: The dimensionality of the encoding.\n",
    "        base_depth: The lowest depth for a layer.\n",
    "\n",
    "    Returns:\n",
    "        encoder: A `callable` mapping a `Tensor` of images to a\n",
    "        `tfd.Distribution` instance over encodings.\n",
    "    \"\"\"\n",
    "    conv = functools.partial(\n",
    "        tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n",
    "\n",
    "    encoder_net = tf.keras.Sequential([\n",
    "        conv(base_depth, 5, 1),\n",
    "        conv(base_depth, 5, 2),\n",
    "        conv(2 * base_depth, 5, 1),\n",
    "        conv(2 * base_depth, 5, 2),\n",
    "        conv(4 * latent_size, 7, padding=\"VALID\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(2 * latent_size, activation=None),\n",
    "    ])\n",
    "\n",
    "    def encoder(images):\n",
    "        images = 2 * tf.cast(images, dtype=tf.float32) - 1\n",
    "        net = encoder_net(images)\n",
    "        return tfd.MultivariateNormalDiag(\n",
    "            loc=net[..., :latent_size],\n",
    "            scale_diag=tf.nn.softplus(net[..., latent_size:] +\n",
    "                                    _softplus_inverse(1.0)),\n",
    "            name=\"code\")\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def make_decoder(activation, latent_size, output_shape, base_depth):\n",
    "    \"\"\"Creates the decoder function.\n",
    "\n",
    "    Args:\n",
    "        activation: Activation function in hidden layers.\n",
    "        latent_size: Dimensionality of the encoding.\n",
    "        output_shape: The output image shape.\n",
    "        base_depth: Smallest depth for a layer.\n",
    "\n",
    "    Returns:\n",
    "        decoder: A `callable` mapping a `Tensor` of encodings to a\n",
    "        `tfd.Distribution` instance over images.\n",
    "    \"\"\"\n",
    "    deconv = functools.partial(\n",
    "        tf.keras.layers.Conv2DTranspose, padding=\"SAME\", activation=activation)\n",
    "    conv = functools.partial(\n",
    "        tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n",
    "\n",
    "    decoder_net = tf.keras.Sequential([\n",
    "        deconv(2 * base_depth, 7, padding=\"VALID\"),\n",
    "        deconv(2 * base_depth, 5),\n",
    "        deconv(2 * base_depth, 5, 2),\n",
    "        deconv(base_depth, 5),\n",
    "        deconv(base_depth, 5, 2),\n",
    "        deconv(base_depth, 5),\n",
    "        conv(output_shape[-1], 5, activation=None),\n",
    "    ])\n",
    "\n",
    "    def decoder(codes):\n",
    "        original_shape = tf.shape(input=codes)\n",
    "        # Collapse the sample and batch dimension and convert to rank-4 tensor for\n",
    "        # use with a convolutional decoder network.\n",
    "        codes = tf.reshape(codes, (-1, 1, 1, latent_size))\n",
    "        logits = decoder_net(codes)\n",
    "        logits = tf.reshape(\n",
    "            logits, shape=tf.concat([original_shape[:-1], output_shape], axis=0))\n",
    "        return tfd.Independent(tfd.Bernoulli(logits=logits),\n",
    "                            reinterpreted_batch_ndims=len(output_shape),\n",
    "                            name=\"image\")\n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def make_mixture_prior(latent_size, mixture_components):\n",
    "    \"\"\"Creates the mixture of Gaussians prior distribution.\n",
    "\n",
    "    Args:\n",
    "        latent_size: The dimensionality of the latent representation.\n",
    "        mixture_components: Number of elements of the mixture.\n",
    "\n",
    "    Returns:\n",
    "        random_prior: A `tfd.Distribution` instance representing the distribution\n",
    "        over encodings in the absence of any evidence.\n",
    "    \"\"\"\n",
    "    if mixture_components == 1:\n",
    "        # See the module docstring for why we don't learn the parameters here.\n",
    "        return tfd.MultivariateNormalDiag(\n",
    "            loc=tf.zeros([latent_size]),\n",
    "            scale_identity_multiplier=1.0)\n",
    "\n",
    "    loc = tf.compat.v1.get_variable(\n",
    "        name=\"loc\", shape=[mixture_components, latent_size])\n",
    "    raw_scale_diag = tf.compat.v1.get_variable(\n",
    "        name=\"raw_scale_diag\", shape=[mixture_components, latent_size])\n",
    "    mixture_logits = tf.compat.v1.get_variable(\n",
    "        name=\"mixture_logits\", shape=[mixture_components])\n",
    "\n",
    "    return tfd.MixtureSameFamily(\n",
    "        components_distribution=tfd.MultivariateNormalDiag(\n",
    "            loc=loc,\n",
    "            scale_diag=tf.nn.softplus(raw_scale_diag)),\n",
    "        mixture_distribution=tfd.Categorical(logits=mixture_logits),\n",
    "        name=\"prior\")\n",
    "\n",
    "\n",
    "def pack_images(images, rows, cols):\n",
    "    \"\"\"Helper utility to make a field of images.\"\"\"\n",
    "    shape = tf.shape(input=images)\n",
    "    width = shape[-3]\n",
    "    height = shape[-2]\n",
    "    depth = shape[-1]\n",
    "    images = tf.reshape(images, (-1, width, height, depth))\n",
    "    batch = tf.shape(input=images)[0]\n",
    "    rows = tf.minimum(rows, batch)\n",
    "    cols = tf.minimum(batch // rows, cols)\n",
    "    images = images[:rows * cols]\n",
    "    images = tf.reshape(images, (rows, cols, width, height, depth))\n",
    "    images = tf.transpose(a=images, perm=[0, 2, 1, 3, 4])\n",
    "    images = tf.reshape(images, [1, rows * width, cols * height, depth])\n",
    "    return images\n",
    "\n",
    "\n",
    "def image_tile_summary(name, tensor, rows=8, cols=8):\n",
    "    tf.compat.v1.summary.image(\n",
    "        name, pack_images(tensor, rows, cols), max_outputs=1)\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params, config):\n",
    "    \"\"\"Builds the model function for use in an estimator.\n",
    "\n",
    "    Arguments:\n",
    "        features: The input features for the estimator.\n",
    "        labels: The labels, unused here.\n",
    "        mode: Signifies whether it is train or test or predict.\n",
    "        params: Some hyperparameters as a dictionary.\n",
    "        config: The RunConfig, unused here.\n",
    "\n",
    "    Returns:\n",
    "        EstimatorSpec: A tf.estimator.EstimatorSpec instance.\n",
    "    \"\"\"\n",
    "    del labels, config\n",
    "\n",
    "    if params[\"analytic_kl\"] and params[\"mixture_components\"] != 1:\n",
    "        raise NotImplementedError(\n",
    "            \"Using `analytic_kl` is only supported when `mixture_components = 1` \"\n",
    "            \"since there's no closed form otherwise.\")\n",
    "\n",
    "    encoder = make_encoder(params[\"activation\"],\n",
    "                            params[\"latent_size\"],\n",
    "                            params[\"base_depth\"])\n",
    "    decoder = make_decoder(params[\"activation\"],\n",
    "                            params[\"latent_size\"],\n",
    "                            IMAGE_SHAPE,\n",
    "                            params[\"base_depth\"])\n",
    "    latent_prior = make_mixture_prior(params[\"latent_size\"],\n",
    "                                        params[\"mixture_components\"])\n",
    "\n",
    "    image_tile_summary(\n",
    "        \"input\", tf.cast(features, dtype=tf.float32), rows=1, cols=16)\n",
    "\n",
    "    approx_posterior = encoder(features)\n",
    "    approx_posterior_sample = approx_posterior.sample(params[\"n_samples\"])\n",
    "    decoder_likelihood = decoder(approx_posterior_sample)\n",
    "    image_tile_summary(\n",
    "        \"recon/sample\",\n",
    "        tf.cast(decoder_likelihood.sample()[:3, :16], dtype=tf.float32),\n",
    "        rows=3,\n",
    "        cols=16)\n",
    "    image_tile_summary(\n",
    "        \"recon/mean\",\n",
    "        decoder_likelihood.mean()[:3, :16],\n",
    "        rows=3,\n",
    "        cols=16)\n",
    "\n",
    "    # `distortion` is just the negative log likelihood.\n",
    "    distortion = -decoder_likelihood.log_prob(features)\n",
    "    avg_distortion = tf.reduce_mean(input_tensor=distortion)\n",
    "    tf.compat.v1.summary.scalar(\"distortion\", avg_distortion)\n",
    "\n",
    "    if params[\"analytic_kl\"]:\n",
    "        rate = tfd.kl_divergence(approx_posterior, latent_prior)\n",
    "    else:\n",
    "        rate = (approx_posterior.log_prob(approx_posterior_sample)\n",
    "                - latent_prior.log_prob(approx_posterior_sample))\n",
    "    avg_rate = tf.reduce_mean(input_tensor=rate)\n",
    "    tf.compat.v1.summary.scalar(\"rate\", avg_rate)\n",
    "\n",
    "    elbo_local = -(rate + distortion)\n",
    "\n",
    "    elbo = tf.reduce_mean(input_tensor=elbo_local)\n",
    "    loss = -elbo\n",
    "    tf.compat.v1.summary.scalar(\"elbo\", elbo)\n",
    "\n",
    "    importance_weighted_elbo = tf.reduce_mean(\n",
    "        input_tensor=tf.reduce_logsumexp(input_tensor=elbo_local, axis=0) -\n",
    "        tf.math.log(tf.cast(params[\"n_samples\"], dtype=tf.float32)))\n",
    "    tf.compat.v1.summary.scalar(\"elbo/importance_weighted\",\n",
    "                                importance_weighted_elbo)\n",
    "\n",
    "    # Decode samples from the prior for visualization.\n",
    "    random_image = decoder(latent_prior.sample(16))\n",
    "    image_tile_summary(\n",
    "        \"random/sample\",\n",
    "        tf.cast(random_image.sample(), dtype=tf.float32),\n",
    "        rows=4,\n",
    "        cols=4)\n",
    "    image_tile_summary(\"random/mean\", random_image.mean(), rows=4, cols=4)\n",
    "\n",
    "    # Perform variational inference by minimizing the -ELBO.\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "    learning_rate = tf.compat.v1.train.cosine_decay(\n",
    "        params[\"learning_rate\"], global_step, params[\"max_steps\"])\n",
    "    tf.compat.v1.summary.scalar(\"learning_rate\", learning_rate)\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={\n",
    "            \"elbo\":\n",
    "                tf.compat.v1.metrics.mean(elbo),\n",
    "            \"elbo/importance_weighted\":\n",
    "                tf.compat.v1.metrics.mean(importance_weighted_elbo),\n",
    "            \"rate\":\n",
    "                tf.compat.v1.metrics.mean(avg_rate),\n",
    "            \"distortion\":\n",
    "                tf.compat.v1.metrics.mean(avg_distortion),\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "ROOT_PATH = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
    "FILE_TEMPLATE = \"binarized_mnist_{split}.amat\"\n",
    "\n",
    "\n",
    "def download(directory, filename):\n",
    "    \"\"\"Downloads a file.\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if tf.io.gfile.exists(filepath):\n",
    "        return filepath\n",
    "    if not tf.io.gfile.exists(directory):\n",
    "        tf.io.gfile.makedirs(directory)\n",
    "    url = os.path.join(ROOT_PATH, filename)\n",
    "    print(\"Downloading %s to %s\" % (url, filepath))\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def static_mnist_dataset(directory, split_name):\n",
    "    \"\"\"Returns binary static MNIST tf.data.Dataset.\"\"\"\n",
    "    amat_file = download(directory, FILE_TEMPLATE.format(split=split_name))\n",
    "    dataset = tf.data.TextLineDataset(amat_file)\n",
    "    str_to_arr = lambda string: np.array([c == b\"1\" for c in string.split()])\n",
    "\n",
    "    def _parser(s):\n",
    "        booltensor = tf.compat.v1.py_func(str_to_arr, [s], tf.bool)\n",
    "        reshaped = tf.reshape(booltensor, [28, 28, 1])\n",
    "        return tf.cast(reshaped, dtype=tf.float32), tf.constant(0, tf.int32)\n",
    "\n",
    "    return dataset.map(_parser)\n",
    "\n",
    "\n",
    "def build_fake_input_fns(batch_size):\n",
    "    \"\"\"Builds fake MNIST-style data for unit testing.\"\"\"\n",
    "    random_sample = np.random.rand(batch_size, *IMAGE_SHAPE).astype(\"float32\")\n",
    "\n",
    "    def train_input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            random_sample).map(lambda row: (row, 0)).batch(batch_size).repeat()\n",
    "        return tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "\n",
    "    def eval_input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            random_sample).map(lambda row: (row, 0)).batch(batch_size)\n",
    "        return tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "\n",
    "    return train_input_fn, eval_input_fn\n",
    "\n",
    "\n",
    "def build_input_fns(data_dir, batch_size):\n",
    "    \"\"\"Builds an Iterator switching between train and heldout data.\"\"\"\n",
    "\n",
    "    # Build an iterator over training batches.\n",
    "    def train_input_fn():\n",
    "        dataset = static_mnist_dataset(data_dir, \"train\")\n",
    "        dataset = dataset.shuffle(50000).repeat().batch(batch_size)\n",
    "        return tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "\n",
    "    # Build an iterator over the heldout set.\n",
    "    def eval_input_fn():\n",
    "        eval_dataset = static_mnist_dataset(data_dir, \"valid\")\n",
    "        eval_dataset = eval_dataset.batch(batch_size)\n",
    "        return tf.compat.v1.data.make_one_shot_iterator(eval_dataset).get_next()\n",
    "\n",
    "    return train_input_fn, eval_input_fn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "\n",
    "\n",
    "    params = FLAGS.flag_values_dict()\n",
    "    params[\"activation\"] = getattr(tf.nn, params[\"activation\"])\n",
    "    if FLAGS.delete_existing and tf.io.gfile.exists(FLAGS.model_dir):\n",
    "        tf.compat.v1.logging.warn(\"Deleting old log directory at {}\".format(\n",
    "            FLAGS.model_dir))\n",
    "        tf.io.gfile.rmtree(FLAGS.model_dir)\n",
    "    tf.io.gfile.makedirs(FLAGS.model_dir)\n",
    "\n",
    "    if FLAGS.fake_data:\n",
    "        train_input_fn, eval_input_fn = build_fake_input_fns(FLAGS.batch_size)\n",
    "    else:\n",
    "        train_input_fn, eval_input_fn = build_input_fns(FLAGS.data_dir,\n",
    "                                                        FLAGS.batch_size)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn,\n",
    "        params=params,\n",
    "        config=tf.estimator.RunConfig(\n",
    "            model_dir=FLAGS.model_dir,\n",
    "            save_checkpoints_steps=FLAGS.viz_steps,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for _ in range(FLAGS.max_steps // FLAGS.viz_steps):\n",
    "        estimator.train(train_input_fn, steps=FLAGS.viz_steps)\n",
    "        eval_results = estimator.evaluate(eval_input_fn)\n",
    "        print(\"Evaluation_results:\\n\\t%s\\n\" % eval_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() missing 1 required positional argument: 'argv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e67222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a22756e69783a2f2f2f7661722f72756e2f646f636b65722e736f636b227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f70616e74656c69732e6d6f6e6f67696f756469732f6c6f63616c2f7765622f73697465732f636f75727365732f646174615f6d696e696e672f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/data_mining/data_mining/aiml-common/lectures/vae/elbo-optimization/elbo_optimization.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     main()\n",
      "\u001b[0;31mTypeError\u001b[0m: main() missing 1 required positional argument: 'argv'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
