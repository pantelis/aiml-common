{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems \n",
    "\n",
    "A recommendation system helps users find compelling content in a large corpora. For example, the Google Play Store provides millions of apps, while YouTube provides billions of videos. More apps and videos are added every day. How can users find new and compelling content? Yes, one can use search to access content. However, a recommendation engine can display items that users might not have thought to search for on their own.\n",
    "\n",
    "In this assignment you will use the [MovieLens dataset](https://grouplens.org/datasets/movielens/latest) called `ml-latest`. You are free to experiment and develop your code with the `ml-latest-small` dataset but you need to **submit** your work with the `ml-latest` dataset which is much larger and will lead to better results. The `ml-latest` dataset consists of several files:\n",
    "\n",
    "* `genome-scores.csv`: a relevance score that a particular movie has a particular tag. Tags are things like \"action\", \"romance\", \"violence\", etc. The relevance score ranges from 0 to 1. The higher the score, the more relevant the tag is to the movie.\n",
    "* `genome-tags.csv`: the tag name for each tag id.\n",
    "* `links.csv`: the id of the movie on MovieLens, the id of the movie on IMDB, and the id of the movie on TMDB.\n",
    "* `movies.csv`: the id of the movie on MovieLens, the title of the movie, and a list of genres associated with the movie.\n",
    "* `ratings.csv`: the id of the movie on MovieLens, the id of the user rating the movie, the rating, and the timestamp of the rating.\n",
    "* `tags.csv`: the id of the movie on MovieLens, the id of the user tagging the movie, the tag, and the timestamp of the tag.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: SVD for Recommendations (30 points)\n",
    "\n",
    "Go over the [recommendation system overview](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf) and write below what matrix factorization can offer and what challenges it faces. To do so, consult the [Surprise](http://surpriselib.com/) library and choose the SVD API of `surpise.prediction_algorithms`. Describe all equations involved and why they turn out to be the way they are. \n",
    "\n",
    "NOTE1: In this task you are expected to do some reading and consultation of APIs. Be as descriptive as possible so that a novice computer scientist can understand your answer. There is no minimum of max \"page limit\". Pay particular attention to [this reference](https://sifter.org/~simon/journal/20061211.html)\n",
    "\n",
    "NOTE2: Although we have recommended the Surprise library, it is worth mentioning that Microsoft has a [recommender system toolkit](https://github.com/microsoft/recommenders). Since recommendation systems are almost everywhere you look in commercial / consumer applications, you may want to spend the time after this assignment to learn more about the field."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here or in a separate markdown file + images**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the SVD based matrix facrorization algorithm (40 points)\n",
    "\n",
    "Implement the matrix factorization algorithm on the movielens data using the surprise API. You need to provide a clear explanation of the code you wrote and you need to report and explain the recommendation metric on a test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 code starts here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Perform hyperparameter tuning (30 points)\n",
    "\n",
    "In this task, you will borrow candidate hyperparameter values from [here](https://github.com/microsoft/recommenders/blob/main/examples/04_model_select_and_optimize/nni_surprise_svd.ipynb) but implement a simple random search to tune them. You can use [Optuna](https://optuna.org/) for such exercise. You need to report the best hyperparameters and the corresponding recommendation metric on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 code starts here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
